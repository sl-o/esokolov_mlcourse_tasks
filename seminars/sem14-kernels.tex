\documentclass[12pt,fleqn]{article}
\usepackage{../lecture-notes/vkCourseML}
\usepackage{xcolor}
%\usepackage[a4paper]{geometry}

\begin{document}
\title{Машинное обучение, ФКН ВШЭ\\Семинар №14}
\author{}
\date{}
\maketitle

\section{Условные задачи оптимизации}

\begin{vkProblem}
	Решите следующую задачу условной оптимизации:
	\[
	\left\{
	\begin{aligned}
	& (x-4)^2 + (y-4)^2 \to \min_{x, y} \\
	& x+y \leq 4, \\
	& x+3y \leq 9.
	\end{aligned}
	\right.
	\]
\end{vkProblem}

\begin{esSolution}
	Выпишем лагранжиан:
	\[
	L(x, y, \lambda_1, \lambda_2)
	=
	(x-4)^2 + (y-4)^2 + \lambda_1(x+y-4) + \lambda_2(x+3y-9).
	\]
	Условия Куна--Таккера запишутся в~виде:
	\[
	\left\{
	\begin{aligned}
	& 2(x-4)+\lambda_1+\lambda_2 = 0, \\
	& 2(y-4)+\lambda_1+3\lambda_2 = 0, \\
	& x+y \leq 4,\; \lambda_1 \geqslant 0,\; \lambda_1(x+y -4)=0, \\
	& x+3y \leq 9,\; \lambda_2 \geqslant 0,\; \lambda_2(x+3y -9)=0.
	\end{aligned}
	\right.
	\]
	Решая их, рассмотрим 4 случая:
	\begin{itemize}
		\item
		$x+y = 4$,\: $x+3y = 9$,\: $\lambda_1\ge0$,\: $\lambda_2\ge0$.\\
		Два эти уравнения дают $(x=\frac32,y=\frac52)$.
		После подстановки в~первые два уравнения условий Куна--Таккера, получаем
		\[
		\begin{cases}
		2(\frac32-4)+\lambda_1+\lambda_2 = 0;\\
		2(\frac52-4)+\lambda_1+3\lambda_2 = 0,
		\end{cases}
		\]
		откуда $\lambda_2 = -1$, что противоречит принятым условиям.
		\item
		$x+y = 4$,\: $x+3y \le 9$,\: $\lambda_1\ge0$,\: $\lambda_2=0$.\\
		Подстановка $\lambda_2=0$ в первые два уравнения условий Куна--Таккера вместе с~уравнением $x+y = 4$ дают решение $(x=2, y=2, \lambda_1 = 4, \lambda_2=0)$.
		Эти решения удовлетворяют всем условиям Куна--Таккера.
		\item
		Два оставшихся случая, как и первый, ведут к противоречиям.
	\end{itemize}
	
	Поскольку задача выпуклая и удовлетворяет ослабленным условиям Слейтера,
	найденная точка является решением.
\end{esSolution}


\section{Построение ядер}

Напомним, что ядром мы называем функцию~$K(x, z)$,
представимую в виде скалярного произведения в некотором
пространстве:~$K(x, z) = \langle \phi(x), \phi(z) \rangle$,
где~$\phi:~\XX~\to~H$~--- отображение из исходного признакового пространства
в некоторое~\emph{спрямляющее пространство} $H$. 

Вспомним, какие функции в принципе могут быть ядрами --- по теореме Мерсера 
функция $K(x, z)$ является ядром тогда и только тогда, когда:
\begin{enumerate}
	\item Она симметрична: $K(x, z) = K(z, x)$.
	\item Она неотрицательно определена, то есть для
	любой конечной выборки~$(x_1, \dots, x_\ell)$
	матрица~$K = \bigl( K(x_i, x_j) \bigr)_{i, j = 1}^{\ell}$
	неотрицательно определена.
\end{enumerate}

\begin{vkProblem}
	Покажите, что если~$K(x, z)$~--- ядро, то оно симметрично
	и неотрицательно определено.
\end{vkProblem}

\begin{esSolution}
	Функция $K(x, z)$~--- ядро, то есть она определяет скалярное произведение
	в некотором пространстве: $K(x, z) = \langle \phi(x), \phi(z) \rangle$.
	Симметричность этой функции вытекает из симметричности скалярного 
	произведения.
	
	Покажем неотрицательную определенность.
	Пусть~$(x_1, \dots, x_\ell)$~--- выборка,
	а~$K = \bigl( K(x_i, x_j) \bigr)_{i, j = 1}^{\ell}$~--- матрица ядра,
	соответствующая ей.
	Тогда для произвольного вектора~$v$:
	\begin{align*}
		\langle K v, v \rangle
		&=
		\sum_{i, j = 1}^{\ell} v_i v_j K(x_i, x_j)
		=\\
		&=
		\sum_{i, j = 1}^{\ell} v_i v_j \langle \phi(x_i), \phi(x_j) \rangle
		=\\
		&=
		\sum_{i, j = 1}^{\ell} \langle v_i \phi(x_i), v_j \phi(x_j) \rangle
		=\\
		&=
		\left\langle
		\sum_{i = 1}^{\ell} v_i \phi(x_i), \sum_{j = 1}^{\ell} v_j \phi(x_j)
		\right\rangle
		=\\
		&=
		\left\|
		\sum_{i = 1}^{\ell} v_i \phi(x_i)
		\right\|^2
		\geq 0.
	\end{align*}
	Мы доказали неотрицательную определенность матрицы~$K$,
	а значит и ядра~$K(x, z)$.
\end{esSolution}

Вместо того, чтобы проверять эти свойства, можно сразу составлять ядра по 
фиксированным правилам. Вспомним две следующие теоремы.

\begin{vkTheorem}
	\label{th:kernelConstr}
	Пусть~$K_1(x, z)$ и~$K_2(x, z)$~--- ядра, заданные на множестве~$\XX$,
	$f(x)$~--- вещественная функция на~$\XX$,
	$\phi: \XX \to \RR^N$~--- векторная функция на~$\XX$,
	$K_3$~--- ядро, заданное на~$\RR^N$.
	Тогда следующие функции являются ядрами:
	\begin{enumerate}
		\item $K(x, z) = K_1(x, z) + K_2(x, z)$,
		\item $K(x, z) = \alpha K_1(x, z)$, $\alpha > 0$,
		\item $K(x, z) = K_1(x, z) K_2(x, z)$,
		\item $K(x, z) = f(x) f(z)$,
		\item $K(x, z) = K_3(\phi(x), \phi(z))$.
	\end{enumerate}
\end{vkTheorem}

\begin{vkTheorem}
	\label{th:kernelLim}
	Пусть~$K_1(x, z), K_2(x, z), \dots$~--- последовательность ядер,
	причем предел
	\[
	K(x, z)
	=
	\lim_{n \to \infty}
	K_n(x, z)
	\]
	существует для всех~$x$ и~$z$.
	Тогда~$K(x, z)$~--- ядро.
\end{vkTheorem}

\begin{vkProblem}
	Покажите, что произведение ядер является ядром~(третий пункт
	теоремы~\ref{th:kernelConstr}).
\end{vkProblem}

\begin{esSolution}
	Пусть ядро~$K_1$ соответствует отображению~$\phi_1: \XX \to \RR^{d_1}$,
	а ядро~$K_2$~--- отображению~$\phi_2: \XX \to \RR^{d_2}$.
	Определим новое отображение, которое соответствует всевозможным
	произведениям признаков из первого и второго спрямляющих пространств:
	\[
	\phi_3(x)
	=
	\left(
	\left( \phi_1(x) \right)_i
	\left( \phi_2(x) \right)_j
	\right)_{i, j = 1}^{d_1, d_2}.
	\]
	Соответствующее этому спрямляющему пространству ядро примет вид
	\begin{align*}
		K_3(x, z)
		&=
		\langle \phi_3(x), \phi_3(z) \rangle
		=\\
		&=
		\sum_{i = 1}^{d_1} \sum_{j = 1}^{d_2}
		\left( \phi_3(x) \right)_{ij}
		\left( \phi_3(z) \right)_{ij}
		=\\
		&=
		\sum_{i = 1}^{d_1}
		\left( \phi_1(x) \right)_i
		\left( \phi_1(z) \right)_i
		\sum_{j = 1}^{d_2}
		\left( \phi_2(x) \right)_j
		\left( \phi_2(z) \right)_j
		=\\
		&=
		K_1(x, z) K_2(x, z).
	\end{align*}
	Мы показали, что произведение двух ядер соответствует скалярному
	произведению в некотором спрямляющем пространстве,
	а значит является ядром.
\end{esSolution}

\begin{vkProblem}
	Пусть~$p(x)$~--- многочлен с положительными коэффициентами.
	Покажите, что~$K(x, z) = p(\langle x, z \rangle)$~--- ядро.
\end{vkProblem}

\begin{esSolution}
	Пусть многочлен имеет вид
	\[
	p(x) = \sum_{i = 0}^{m} a_i x^i.
	\]
	
	Будем доказывать требуемое утверждение по шагам.
	\begin{enumerate}
		\item $\langle x, z \rangle$~---ядро по определению~($\phi(x) = x$);
		\item $\langle x, z \rangle^i$~--- ядро как произведение ядер;
		\item $a_i \langle x, z \rangle^i$~--- ядро как произведение 
		положительной
		константы на ядро;
		\item константный член~$a_0$~--- ядро по пункту 4 
		теоремы~\ref{th:kernelConstr},
		где~$f(x) = \sqrt{a_0}$;
		\item $\sum_{i = 0}^{m} a_i \langle x, z \rangle^i$~--- ядро
		как линейная комбинация ядер.
	\end{enumerate}
\end{esSolution}

\subsection{Спрямляющие пространства}
	\par Иногда может оказаться полезным знать не только вид ядра $K(x, z),$ но и вид преобразования $\phi(x),$ и наоборот. Рассмотрим данный переход на нескольких примерах.
\begin{vkProblem}
	Рассмотрим ядро на пространстве всех подмножеств конечного множества $D$:
	$$K(A_1, A_2) = 2^{\left| A_1 \cap A_2 \right|}.$$
	Покажите, что оно соответствует отображению в $2^{|D|}$-мерное пространство
	\begin{align*}
		\left( \phi(A) \right)_U = \begin{cases}
			1, U \subseteq A,\\
			0, \text{иначе,}
		\end{cases}
	\end{align*}
	где $U$ пробегает по всем подмножествам множества $D$.
\end{vkProblem}

\begin{esSolution}
	Покажем, что при использовании указанного отображения $\phi(A)$ скалярное произведение в спрямляющем пространстве действительно имеет указанный вид:
	\begin{align*}
		\langle \phi(A_1), \phi(A_2) \rangle = 
		\sum_{U \subseteq D} \left(\phi(A_1) \right)_U \left(\phi(A_2) \right)_U.
	\end{align*}
	Заметим, что $ \left(\phi(A_1) \right)_U \left(\phi(A_2) \right)_U = 1$ только в том случае, если $ \left(\phi(A_1) \right)_U = 1$ и $ \left(\phi(A_2) \right)_U = 1,$ т.е. если $U \subseteq A_1$ и $U \subseteq A_2.$ Таким образом,
	\begin{align*}
		\langle \phi(A_1), \phi(A_2) \rangle = 
		\left| \{ U \subseteq D \cond U \subseteq A_1, U \subseteq A_2 \} \right|.
	\end{align*}
	Подсчитаем количество таких множеств. Рассмотрим некоторое $U \subseteq A_1 \cap A_2.$ Заметим, что все прочие подмножества $D$ не будут удовлетворять хотя бы одному из условий, в то время как для таким образом выбранного $U$ выполняются оба, поэтому необходимое число — число различных подмножеств $A_1 \cap A_2.$ Оно, в свою очередь, равно $2^{\left| A_1 \cap A_2 \right|}.$
\end{esSolution}

\begin{vkProblem}
	Рассмотрим ядро
	$$K(x, z) = \prod_{j=1}^d (1+x_j z_j).$$
	Какому спрямляющему пространству оно соответствует?
\end{vkProblem}

\begin{esSolution}
	Раскроем скобки в выражении для $K(x, z).$ Заметим, что итоговое выражение будет включать мономы всех чётных степеней от 0 до $2d$ включительно. При этом мономы степени $2k, \, k \in \{ 0, \dots, d\},$ формируются следующим образом: из~$d$ скобок, входящих в произведение, случайным образом выбираются $k$, после чего входящие в них слагаемые вида $x_j z_j$ умножаются на единицы, входящие в состав остальных $d-k$ скобок. Таким образом, в итоговое выражение входят все мономы степени $2k$ над всеми наборами из $k$ различных исходных признаков, и только они. Запишем это формально:
	\begin{align*}
		K(x, z) = (1+x_1 z_1) (1 + x_2 z_2) \dots (1 + x_d z_d)	=
		\sum_{k=0}^d \sum_{\substack{D \subseteq \{1, \dots, d\} \\ |D| = k}} ёб \prod_{j \in D} x_j z_j.
	\end{align*}
	
	Для простоты понимания приведем вид итогового выражения для $d = 2, 3$ (несложно убедиться в его справедливости путём раскрытия скобок):
	\begin{align*}
		K((x_1, x_2), (z_1, z_2)) =&\ 1 + x_1 z_1 + x_2 z_2 + x_1 x_2 z_1 z_2, \\
		K((x_1, x_2, x_3), (z_1, z_2, z_3)) =&\ 1 + x_1 z_1 + x_2 z_2 + x_3 z_3 + x_1 x_2 z_1 z_2 + \\
		&x_1 x_3 z_1 z_3 + x_2 x_3 z_2 z_3 + x_1 x_2 x_3 z_1 z_2 z_3.			
	\end{align*}
	Таким образом, объект $x$ в спрямляющем пространстве представим в следующем виде:
	\begin{align*}
		\phi(x) = \left( 1, x_1, \dots, x_d, x_1 x_2, \dots, x_1 x_d, \dots , x_{d-1} x_d, \dots, x_1 x_2 \dots x_d\right) =
		\left( \prod_{j \in D} x_j \right)_{D \subseteq \{1, \dots, d\}},
	\end{align*}
	то есть в виде вектора мономов всех степеней над наборами различных признаков в исходном пространстве.
\end{esSolution}
\newpage
\begin{vkProblem}
	\label{pr:gauss}
	Пусть $ \{(x_i, y_i)\}_{i=1}^\ell, \, y_i \in \{-1, +1\}$ — произвольная выборка, а $\phi(x)$ "--- отображение в спрямляющее пространство, соответствующее гауссову ядру. Покажите, что в данном спрямляющем пространстве существует линейный классификатор, безошибочно разделяющий выборку $\phi(x_1), \dots, \phi(x_\ell).$
\end{vkProblem}

\begin{esSolution}
	Покажем, что вектор весов $w$ в спрямляющем пространстве может быть найден как линейная комбинация объектов выборки $\phi(x_1), \dots, \phi(x_\ell),$ т.е. $w = \sum_{i=1}^\ell \alpha_i \phi(x_i).$ Запишем условие верной классификации каждого из объектов выборки в спрямляющем пространстве:
	\begin{align*}
		\langle w, \phi(x_i) \rangle = y_i, \, i = \overline{1, \ell}. 
	\end{align*}
	Заметим, что записанное нами условие является более строгим, чем необходимо, однако в дальнейшем мы покажем существование $w,$ удовлетворяющего этим более строгим ограничениям. Преобразуем:
	\begin{align*}
		\left\langle \sum_{j=1}^\ell \alpha_j \phi(x_j), \phi(x_i) \right\rangle = y_i, \, i = \overline{1, \ell},\\
		\sum_{j=1}^\ell \alpha_j \langle \phi(x_j), \phi(x_i) \rangle = y_i, \, i = \overline{1, \ell},\\
		\sum_{j=1}^\ell \alpha_j K(x_i, x_j) = y_i, \, i = \overline{1, \ell}.	
	\end{align*}
	Таким образом, мы получили систему из $\ell$ линейных уравнений на $\alpha_1, \dots, \alpha_\ell,$ при этом матрицей системы является матрица Грама, являющаяся невырожденной (согласно утв. 1.3 лекции 13), а потому система имеет решение, и соответствующий вектор $w$ существует.
\end{esSolution}
	
\subsection{Ядра в метрических методах}
	Теперь, когда у нас есть общее представление о природе ядер, попробуем использовать их для усовершенствования уже известных нам методов — например, метрических. Как вы знаете, для использования данного класса алгоритмов необходимо задать функцию расстояния на пространстве объектов — однако при использовании ядер у нас не всегда есть возможность выразить $\phi(x)$ в явном виде. Тем не менее, оказывается, ядро содержит в себе 
	много информации о спрямляющем пространстве,
	и позволяет производить в нем различные операции, не зная самого
	отображения~$\phi(x)$.
\begin{vkProblem}
	Как вычислить норму вектора~$\phi(x)$, зная лишь ядро~$K(x, z)$?
\end{vkProblem}

\begin{esSolution}
	\[
	\|\phi(x)\|
	=
	\sqrt{\|\phi(x)\|^2}
	=
	\sqrt{\langle \phi(x), \phi(x) \rangle}
	=
	\sqrt{K(x, x)}.
	\]
\end{esSolution}

\begin{vkProblem}
	Как вычислить расстояние между векторами~$\phi(x)$
	и~$\phi(z)$, зная лишь ядро~$K(x, z)$?
\end{vkProblem}

\begin{esSolution}
	\begin{align*}
	\rho^2(\phi(x), \phi(z))
	&=
	\|\phi(x) - \phi(z)\|^2
	=
	\langle \phi(x) - \phi(z), \phi(x) - \phi(z) \rangle
	=\\
	&=
	\langle \phi(x), \phi(x) \rangle -
	2 \langle \phi(x), \phi(z) \rangle +
	\langle \phi(z), \phi(z) \rangle
	=\\
	&=
	K(x, x) - 2 K(x, z) + K(z, z).
	\end{align*}
\end{esSolution}

Таким образом, ядра можно использовать и в метрических методах~(например, 
kNN)~---
достаточно подставить в них в качестве функции расстояния
величину~$\sqrt{K(x, x) - 2 K(x, z) + K(z, z)}$.


\section{Метод опорных векторов}
\begin{vkProblem}
    Рассмотрим задачу с линейно разделимой выборкой.
    Допустим, мы решили двойственную задачу SVM и нашли вектор двойственных переменных~$\lambda$.
    Покажите, что половина ширины разделяющей полосы~$\rho$ может быть вычислена по следующей
    формуле:
    \[
        \frac{1}{\rho^2}
        =
        \sum_{i = 1}^{\ell} \lambda_i.
    \]
\end{vkProblem}

\begin{esSolution}
    Поскольку выборка линейно разделима, то все объекты, для которых \\ $\lambda_i \neq 0$,
    окажутся на границе разделяющей полосы.
    Для них будет выполнено равенство
    \[
        y_i \left(\langle w, x_i \rangle + b \right) = 1,
    \]
    из которого можно выразить~$b$:
    \[
        b = y_i - \langle w, x_i \rangle.
    \]
    Домножим обе стороны на~$\lambda_i y_i$ и просуммируем по~$i$ (заметим, что для объектов не на границе разделяющей полосы выполняется $\lambda_i y_i = 0$):
    \[
        b \sum_{i = 1}^{\ell} \lambda_i y_i
        =
        \sum_{i = 1}^{\ell} \lambda_i y_i^2
        -
        \sum_{i = 1}^{\ell} \lambda_i y_i \langle w, x_i \rangle.
    \]
    Поскольку~$w$, $b$ и~$\lambda$ здесь~--- решения прямой и двойственной задач,
    то для них выполнены условия Куна-Таккера.
    В частности,
    \begin{align*}
        & \sum_{i = 1}^{\ell} \lambda_i y_i = 0,\\
        & w = \sum_{i = 1}^{\ell} \lambda_i y_i x_i.
    \end{align*}
    Заметим также, что~$y_i^2 = 1$.
    Воспользовавшись этими тремя равенствами, получаем:
    \[
        0
        =
        \sum_{i = 1}^{\ell} \lambda_i
        -
        \|w\|^2.
    \]
    Ранее мы доказали, что в SVM ширина разделяющей полосы равна~$\frac{2}{\|w\|}$, поэтому
    \[
        0
        =
        \sum_{i = 1}^{\ell} \lambda_i
        -
        \frac{1}{\rho^2}.
    \]
    Отсюда получаем требуемое равенство.
\end{esSolution}

\begin{vkProblem}
	Пусть~$(w, b, \xi_1, \dots, \xi_{\ell})$~---
	оптимальное решение прямой задачи~SVM.
	Предположим, что $\xi_3 > 0$.
	Выразите отступ объекта~$x_3$ для~обученного линейного классификатора
	через значения $(\xi_1, \dots, \xi_{\ell})$.
\end{vkProblem}
%2W(x - As)

\begin{esSolution}
	Заметим, что, поскольку $\xi_3 >0,$ то объект $x_3$ является опорным нарушителем. Отсюда следует, что $\lambda_3 = C.$ Напомним, что для двойственной задачи можно записать условия дополняющей нежесткости:
	\begin{align*}
		\lambda_3 [y_3 \left( \langle w, x_3\rangle + b  \right) - 1 + \xi_3] = 0,
	\end{align*}
	откуда можно получить, что $y_3 \left( \langle w, x_3\rangle + b \right) - 1 + \xi_3 = 0 \Leftrightarrow M_3 = y_3 \left( \langle w, x_3\rangle + b  \right) = 1 - \xi_3.$
\end{esSolution}

\begin{vkProblem}
	Пусть мы решили двойственную задачу SVM и получили
	решение~$(\lambda_1, \dots, \lambda_{\ell})$.
	Пусть мы также восстановили оптимальный порог~$b$.
	Выразите:
	\begin{enumerate}
		\item Квадрат нормы~$\|w\|^2$ оптимального вектора~$w$ для~прямой задачи;
		\item Сумму~$\sum_{i=1}^{\ell} \xi_i$ оптимальных значений
		параметров $\xi_1, \dots, \xi_{\ell}$ для прямой задачи.
	\end{enumerate}
\end{vkProblem}

\vspace{1cm}

\begin{esSolution}
	\begin{enumerate}
		\item 
	Напомним, что из условий Куна-Таккера для двойственной задачи имеем $w = \sum_{i=1}^\ell \lambda_i y_i x_i$. Отсюда
	\begin{align*}
		\|w\|^2 = \langle w, w\rangle = \left\langle \sum_{i=1}^\ell \lambda_i y_i x_i, \sum_{j=1}^\ell \lambda_j y_j x_j \right\rangle = \sum_{i, j = 1}^\ell \lambda_i \lambda_j y_i y_j \langle x_i, x_j\rangle.
	\end{align*}
	\item Напомним, что имеет место
	\begin{align*}
		\mu_i \xi_i =0 \Leftrightarrow (\mu_i = 0) \text{ или } (\xi_i = 0),
	\end{align*}
	поэтому имеет смысл рассматривать лишь те объекты, для которых $\mu_i = 0.$ Из $\lambda_i + \mu_i = C$ имеем $\lambda_i = C \ne 0.$ Отсюда и из $\lambda_i [y_i \left( \langle w, x_i\rangle + b  \right) - 1 + \xi_i] = 0$ имеем 
	\begin{align*}
		&y_i \left( \langle w, x_i\rangle + b  \right) - 1 + \xi_i = 0 \Leftrightarrow \xi_i = 1 - y_i \left( \langle w, x_i\rangle + b  \right) = \\
		&= 1 - y_i \left( \left\langle \sum_{j=1}^\ell \lambda_j y_j x_j , x_i \right\rangle + b  \right) = 1 - y_i \left( \sum_{j=1}^\ell \lambda_j y_j \langle x_i, x_j\rangle + b\right).
	\end{align*}
	
	Отсюда имеем:
	\begin{align*}
		\sum_{[i=1]}^{\ell} \xi_i = \sum_{i=1}^\ell \left( 1 - y_i \left( \sum_{j=1}^\ell \lambda_j y_j \langle x_i, x_j\rangle + b\right) \right) = \\
		= \ell - \sum_{i=1}^\ell \sum_{j=1}^\ell y_i y_j \lambda_j \langle x_i, x_j\rangle - b \sum_{i=1}^\ell y_i. 
	\end{align*}
	\end{enumerate}
\end{esSolution}


\end{document} 
